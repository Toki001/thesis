{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import albumentations as A\n",
    "from albumentations.tensorflow import ToTensorV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.Blur(blur_limit=3, p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, fill_value=0, p=0.4),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_image_datasets(input_dataset, output_dataset, split_ratios=(0.7, 0.2, 0.1)):\n",
    "\n",
    "     if not (0.999 < sum(split_ratios) < 1.001):\n",
    "             raise ValueError('split_ratios must sum to 1')\n",
    "\n",
    "     input_ds_path = Path(input_dataset)\n",
    "     output_ds_path = Path(output_dataset)\n",
    "\n",
    "     if not input_ds_path.is_dir():\n",
    "         print(f'Source directory {input_ds_path.name} does not exist')\n",
    "         return\n",
    "\n",
    "     train_path = output_ds_path / 'train'\n",
    "     test_path = output_ds_path / 'test'\n",
    "     val_path = output_ds_path / 'val'\n",
    "\n",
    "     class_names = [d.name for d in input_ds_path.iterdir() if d.is_dir()]\n",
    "\n",
    "     if not class_names:\n",
    "         print(f'Source directory {input_ds_path.name} does not contain any class names')\n",
    "         return\n",
    "\n",
    "     for directory in [train_path, test_path, val_path]:\n",
    "         for class_name in class_names:\n",
    "             (directory / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "     for class_name in class_names:\n",
    "\n",
    "         class_source_path = input_ds_path / class_name\n",
    "\n",
    "         files = [f for f in class_source_path.iterdir() if f.is_file()]\n",
    "\n",
    "         random.shuffle(files)\n",
    "\n",
    "         total_files = len(files)\n",
    "         train_end = int(total_files * split_ratios[0])\n",
    "         test_end = train_end + int(total_files * split_ratios[1])\n",
    "\n",
    "         split_data = {\n",
    "             'train': (files[:train_end], train_path),\n",
    "             'test': (files[train_end:test_end], test_path),\n",
    "             'val': (files[test_end:], val_path)\n",
    "         }\n",
    "\n",
    "         print(f\"Copying {class_name} to {output_ds_path}\")\n",
    "\n",
    "         for split_name, (file_list, destination_path) in split_data.items():\n",
    "\n",
    "             dest_class_path = destination_path / class_name\n",
    "\n",
    "             for file_path in tqdm(file_list, desc=f'Copying {split_name} files'):\n",
    "\n",
    "                 shutil.copy2(file_path, dest_class_path / file_path.name)\n",
    "\n",
    "         print(f'Copying {class_name} finished!')\n",
    "\n",
    "     print(\"Data splitting successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_dir = r'/Users/jameskierdoliguez/Desktop/rice_leaf/dataset'\n",
    "output_dataset_dir = r'/Users/jameskierdoliguez/Desktop/rice_leaf/aug_dataset'\n",
    "\n",
    "if not input_dataset_dir or not output_dataset_dir:\n",
    "    raise ValueError('Source and base data directory not found')\n",
    "\n",
    "prepare_image_datasets(input_dataset_dir, output_dataset_dir, split_ratios=(0.7, 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiceLeafDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory, transform=None, batch_size=32, shuffle=True):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.classes = sorted(os.listdir(directory))\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            cls_folder = os.path.join(directory, cls)\n",
    "            for img_name in os.listdir(cls_folder):\n",
    "                self.image_paths.append(os.path.join(cls_folder, img_name))\n",
    "                self.labels.append(idx)\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images, labels = [], []\n",
    "        for i in batch_indices:\n",
    "            image = cv2.imread(self.image_paths[i])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            label = self.labels[i]\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)[\"image\"]\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        images = np.stack(images)\n",
    "        labels = tf.keras.utils.to_categorical(labels, num_classes=len(self.classes))\n",
    "        return images, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = RiceLeafDataset(train_dir, transform=train_transform, batch_size=batch_size)\n",
    "val_gen = RiceLeafDataset(val_dir, transform=val_transform, batch_size=batch_size, shuffle=False)\n",
    "test_gen = RiceLeafDataset(test_dir, transform=val_transform, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:150]:  # Keep lower layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"efficientnet_rice_leaf_albu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_gen:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "class_labels = test_gen.classes\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
